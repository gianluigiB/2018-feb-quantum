{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copy of GPT-2.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/gianluigiB/2018-feb-quantum/blob/master/test_GPT_2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "00LZr2LU_hOc",
        "colab_type": "code",
        "outputId": "62d8c2f4-4147-4022-a0f5-b87377ae72f1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 139
        }
      },
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/openai/gpt-2"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'gpt-2'...\n",
            "remote: Enumerating objects: 11, done.\u001b[K\n",
            "remote: Counting objects: 100% (11/11), done.\u001b[K\n",
            "remote: Compressing objects: 100% (7/7), done.\u001b[K\n",
            "remote: Total 134 (delta 5), reused 7 (delta 4), pack-reused 123\u001b[K\n",
            "Receiving objects: 100% (134/134), 4.34 MiB | 8.25 MiB/s, done.\n",
            "Resolving deltas: 100% (65/65), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "TeoTtrME_zAF",
        "colab_type": "code",
        "outputId": "942b52f9-4193-4046-e029-5c997489b0fc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "%cd gpt-2"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/gpt-2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "YCPiFaSk_3R3",
        "colab_type": "code",
        "outputId": "2457522d-c3f7-4f32-8ff8-077f147fe03d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 503
        }
      },
      "cell_type": "code",
      "source": [
        "!sh download_model.sh 117M"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Fetching 117M/checkpoint\n",
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "\r  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\r100    77  100    77    0     0    636      0 --:--:-- --:--:-- --:--:--   636\n",
            "Fetching 117M/encoder.json\n",
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "\r  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\r100 1017k  100 1017k    0     0  10.2M      0 --:--:-- --:--:-- --:--:-- 10.2M\n",
            "Fetching 117M/hparams.json\n",
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "\r  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\r100    90  100    90    0     0    796      0 --:--:-- --:--:-- --:--:--   796\n",
            "Fetching 117M/model.ckpt.data-00000-of-00001\n",
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "100  474M  100  474M    0     0   128M      0  0:00:03  0:00:03 --:--:--  128M\n",
            "Fetching 117M/model.ckpt.index\n",
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "100  5215  100  5215    0     0  40742      0 --:--:-- --:--:-- --:--:-- 40742\n",
            "Fetching 117M/model.ckpt.meta\n",
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "100  460k  100  460k    0     0  5975k      0 --:--:-- --:--:-- --:--:-- 6054k\n",
            "Fetching 117M/vocab.bpe\n",
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "100  445k  100  445k    0     0  3713k      0 --:--:-- --:--:-- --:--:-- 3713k\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "EyUfJSLG_6-j",
        "colab_type": "code",
        "outputId": "97e77da1-9a9c-4eb2-f1f8-5faf8adddd94",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 364
        }
      },
      "cell_type": "code",
      "source": [
        "!pip3 install -r requirements.txt"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting fire>=0.1.3 (from -r requirements.txt (line 1))\n",
            "  Downloading https://files.pythonhosted.org/packages/5a/b7/205702f348aab198baecd1d8344a90748cb68f53bdcd1cc30cbc08e47d3e/fire-0.1.3.tar.gz\n",
            "Collecting regex==2017.4.5 (from -r requirements.txt (line 2))\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/36/62/c0c0d762ffd4ffaf39f372eb8561b8d491a11ace5a7884610424a8b40f95/regex-2017.04.05.tar.gz (601kB)\n",
            "\u001b[K    100% |████████████████████████████████| 604kB 23.1MB/s \n",
            "\u001b[?25hRequirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from fire>=0.1.3->-r requirements.txt (line 1)) (1.11.0)\n",
            "Building wheels for collected packages: fire, regex\n",
            "  Building wheel for fire (setup.py) ... \u001b[?25ldone\n",
            "\u001b[?25h  Stored in directory: /root/.cache/pip/wheels/2a/1a/4d/6b30377c3051e76559d1185c1dbbfff15aed31f87acdd14c22\n",
            "  Building wheel for regex (setup.py) ... \u001b[?25ldone\n",
            "\u001b[?25h  Stored in directory: /root/.cache/pip/wheels/75/07/38/3c16b529d50cb4e0cd3dbc7b75cece8a09c132692c74450b01\n",
            "Successfully built fire regex\n",
            "\u001b[31mspacy 2.0.18 has requirement numpy>=1.15.0, but you'll have numpy 1.14.6 which is incompatible.\u001b[0m\n",
            "\u001b[31mspacy 2.0.18 has requirement regex==2018.01.10, but you'll have regex 2017.4.5 which is incompatible.\u001b[0m\n",
            "\u001b[31mfastai 1.0.46 has requirement numpy>=1.15, but you'll have numpy 1.14.6 which is incompatible.\u001b[0m\n",
            "Installing collected packages: fire, regex\n",
            "  Found existing installation: regex 2018.1.10\n",
            "    Uninstalling regex-2018.1.10:\n",
            "      Successfully uninstalled regex-2018.1.10\n",
            "Successfully installed fire-0.1.3 regex-2017.4.5\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "H9r5UiqIABAE",
        "colab_type": "code",
        "outputId": "aadf1ef2-9d6b-4014-a0c2-adae6a465ea0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 919
        }
      },
      "cell_type": "code",
      "source": [
        "!python3 src/interactive_conditional_samples.py"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2019-02-27 17:29:25.623135: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2200000000 Hz\n",
            "2019-02-27 17:29:25.625812: I tensorflow/compiler/xla/service/service.cc:150] XLA service 0x1e86520 executing computations on platform Host. Devices:\n",
            "2019-02-27 17:29:25.625857: I tensorflow/compiler/xla/service/service.cc:158]   StreamExecutor device (0): <undefined>, <undefined>\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Colocations handled automatically by placer.\n",
            "WARNING:tensorflow:From /content/gpt-2/src/sample.py:51: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.cast instead.\n",
            "WARNING:tensorflow:From /content/gpt-2/src/sample.py:53: multinomial (from tensorflow.python.ops.random_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.random.categorical instead.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/training/saver.py:1266: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use standard file APIs to check for files with this prefix.\n",
            "Model prompt >>> I wandered lonely as a cloud\n",
            "======================================== SAMPLE 1 ========================================\n",
            " of these winds blew. The trumpet was a crowning outliner, wonderful. I felt that I could sing just about any song. I got so absorbed in it that I knew time just didn't have to be endless, that I avoided bed time for things that made sense to me. Finally we went home. Sandra spoke of the chance to play BIG for the rest of her life--Her name was Crystal together in our arms--she wanted to sing the whole way.\n",
            "\n",
            "--MICHAEL BLZEGAGER<|endoftext|>Video\n",
            "\n",
            "According to one PC gaming expert, jealousy is more prevalent when you're having dinner with an ex than when you're making expressions of disagreement over which is best, or the demented-ness of the girl you are.\n",
            "\n",
            "I was at a European dinner for employees and I noticed a woman commenting that I \"was so naïve\" about stepping away from her. I saw that she was totally avoiding expected danger and was happy to talk about why hotels within a company (and others around businesses across the globe) should have more guards. I agreed in order for me to carry out an interview with six business executives this Rose did about the terrorist warzones, resisted every interview request asking \"where was your order from right away\", and offered a scenario for when stares should seem sharper before doing X 10 x 10 hours and for filet mignon go into an IE 9 notification and wait three minutes for in-person interviews, just be careful once they've given this description of how things are doing.\n",
            "\n",
            "Obviously I wouldn't lie to anyone heeded or spoken over three passive escalators for just a little bit, but it really meant the world to me that my guard would be big enough at 7:30 or 8pm. So I felt better, sacrificing all the time I had on this road and being up until 8 more hours remaining. Besides, I spoke for double what I wanted, my day was already fully booked out, and there was no risk of them seizing it all.\n",
            "\n",
            "We stood in a yard away and kept walking like you expect to get in a point with your loved one 16 or 17 times in the past 16 years. Eventually then we would hit 5:30pm and butler would ask how much dinner I was heading, so everyone was looking mid-east. He would fixates on something and just sit and stare at a controller for a while. Then's shoved in order being prepared at a particularly busy time.\n",
            "\n",
            "We would do additional post-haste\n",
            "================================================================================\n",
            "Model prompt >>> I wandered lonely as a cloud That floats on high o'er vales and hills, When all at once I saw a crowd, A host, of golden daffodils\n",
            "======================================== SAMPLE 1 ========================================\n",
            ", Shaken you to let within. I remembered the size of the oxen he sent, A gorgeous man with fair eyebrows belts hemmed, Of them paused to warm the sweat of his brow. Bathow I gazed with, Reminiscing fair my skin. This prison I can't fathom, But I want to kill. Snowstorms would feign aath with these many of My limbs? I am travelled half as far to innocence As am I ever to the storm, I'll bide While these impure waits, The millinah and their songs whisper I to sleep. Oct. 11, 1870. Virgil, Giver of the Torments.\"\n",
            "\n",
            "ital_Laughs.org wrote:\n",
            "\n",
            "Back in public life, tales from images became encyclopedic about the Ron Paul Presidential campaign. In nineteenth century America it all started with the infamous Invisibility Scaledukk. He was also one of the first to launch the twin reprocessing and desalination for huge power plants by steam. pic.twitter.com/CgBgo9Q5GYw — Mauri Raimondo (@Raimondo4ranland) October 11, 2014\n",
            "\n",
            "Paul has said he will put aside 21st century politics for The Great American Heritage Museum because he's opposed Donald Trump's plans.\n",
            "\n",
            "Nope, no Marquis de Trabert, noseized, Losers–again! — Bill Mundasame (@BillMundasame) October 11, 2014\n",
            "\n",
            "THENE, ll- fans:\n",
            "\n",
            "Harry Kern says \"I really think his style I see won't work in Congress… Just rent massive computers and iPads executes beauty rotaround.\"+(Few Republicans will give Hillary only 8800!!)Titania added \"NULL,\" i will go to the library tomorrow. Cudi (Chicago) Tweezers<|endoftext|>Afghanistan anesthesia therapy helps prolong life | 2012, 2013, 2014 primary care »\n",
            "\n",
            "With U.S. Senator Al Franken on the shortlist of senators to lead the nation in supporting U.S. troops in Afghanistan, congressional staff and health and human services staff have called for Congress to provide safety to all U.S. service members yet again. In conjunction with Faculty Teacher Federation's Institute for Ultrasound Training in EMF Philadelphia, Obama Administration staffers Helper a Retired Army Specialist Teased Fatally and a member of Congress recommended felony violations of ALS by a failed ALS Medical Center technician. Universal Med-Treatment Suggested\n",
            "================================================================================\n",
            "Model prompt >>> "
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}